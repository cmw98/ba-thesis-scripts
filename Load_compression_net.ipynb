{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d519f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "\n",
    "from compressai.datasets import ImageFolder\n",
    "from compressai.zoo import mbt2018\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd9cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = \"mbt2018\"\n",
    "suffix = \"_500ep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e89423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/clemens/vsc-data/mbt/mbt2018_q4_mse_500ep.pth.tar\n",
      "Actual epochs:500\n",
      "/Users/clemens/vsc-data/test_images/c0580.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/c0580.png\n",
      "/Users/clemens/vsc-data/test_images/g0173.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/g0173.png\n",
      "/Users/clemens/vsc-data/test_images/g0601.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/g0601.png\n",
      "/Users/clemens/vsc-data/test_images/g0629.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/g0629.png\n",
      "/Users/clemens/vsc-data/test_images/c0796.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/c0796.png\n",
      "/Users/clemens/vsc-data/test_images/c0972.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/c0972.png\n",
      "/Users/clemens/vsc-data/test_images/g0417.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/g0417.png\n",
      "/Users/clemens/vsc-data/test_images/g0365.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/g0365.png\n",
      "/Users/clemens/vsc-data/test_images/g1053.png\n",
      "/Users/clemens/vsc-data/mbt2018_q4_mse_fullres/g1053.png\n",
      "/Users/clemens/vsc-data/test_images/c0184.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m pad(x)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 37\u001b[0m     out_net \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m out_net[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_hat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m decoded_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/clemens/vsc-data/mbt2018_q\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(quality) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m metric \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fullres\u001b[39m\u001b[38;5;124m'\u001b[39m, file)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/compressai/models/google.py:472\u001b[0m, in \u001b[0;36mJointAutoregressiveHierarchicalPriors.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 472\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh_a(y)\n\u001b[1;32m    474\u001b[0m     z_hat, z_likelihoods \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentropy_bottleneck(z)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/compressai/layers/gdn.py:83\u001b[0m, in \u001b[0;36mGDN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_reparam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma)\n\u001b[1;32m     82\u001b[0m gamma \u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mreshape(C, C, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m norm \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse:\n\u001b[1;32m     86\u001b[0m     norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(norm)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "directory = '/Users/clemens/vsc-data/test_images'\n",
    "\n",
    "def pad (x):\n",
    "    h, w = x.size(2), x.size(3)\n",
    "    p = 64  # maximum 6 strides of 2\n",
    "    new_h = (h + p - 1) // p * p\n",
    "    new_w = (w + p - 1) // p * p\n",
    "    padding_left = (new_w - w) // 2\n",
    "    padding_right = new_w - w - padding_left\n",
    "    padding_top = (new_h - h) // 2\n",
    "    padding_bottom = new_h - h - padding_top\n",
    "    return F.pad(\n",
    "        x,\n",
    "        (padding_left, padding_right, padding_top, padding_bottom),\n",
    "        mode=\"constant\",\n",
    "        value=0,\n",
    "    )\n",
    "\n",
    "for quality in [4, 6, 8]:\n",
    "    for metric in ['mse', 'msssim']:\n",
    "        net = mbt2018(quality=quality, pretrained=False).eval().to(device)\n",
    "        file = \"/Users/clemens/vsc-data/mbt/\" + model + \"_q\" + str(quality) + \"_\" + metric + suffix + \".pth.tar\"\n",
    "        print(file)\n",
    "        checkpoint = torch.load(file, map_location=device)\n",
    "        net.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        print(\"Actual epochs:\" + str(checkpoint[\"epoch\"] + 1))\n",
    "\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.path.join(directory, os.fsdecode(file))\n",
    "            if filename.endswith(\".png\"):\n",
    "                print(filename)\n",
    "                img = Image.open(filename).convert('RGB')\n",
    "                x = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "                x = pad(x)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    out_net = net.forward(x)\n",
    "                out_net['x_hat'].clamp_(0, 1)\n",
    "                \n",
    "                decoded_filename = os.path.join('/Users/clemens/vsc-data/mbt2018_q' + str(quality) + '_' + metric + '_fullres', file)\n",
    "                print(decoded_filename)\n",
    "                save_image(out_net['x_hat'], decoded_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
