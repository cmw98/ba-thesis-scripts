{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cded1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 InterDigital Communications, Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74570886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "\n",
    "from piq import psnr\n",
    "\n",
    "from compressai.datasets import ImageFolder\n",
    "from compressai.zoo import models\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d18e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateDistortionLoss(nn.Module):\n",
    "    \"\"\"Custom rate distortion loss with a Lagrangian parameter.\"\"\"\n",
    "\n",
    "    def __init__(self, lmbda=1e-2):\n",
    "        super().__init__()\n",
    "        self.ms_ssim = ms_ssim\n",
    "        self.psnr = psnr\n",
    "        self.lmbda = lmbda\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        N, _, H, W = target.size()\n",
    "        out = {}\n",
    "        num_pixels = N * H * W\n",
    "\n",
    "        out[\"bpp_loss\"] = sum(\n",
    "            (torch.log(likelihoods).sum() / (-math.log(2) * num_pixels))\n",
    "            for likelihoods in output[\"likelihoods\"].values()\n",
    "        )\n",
    "        \n",
    "        out[\"msssim_loss\"] = self.ms_ssim(output[\"x_hat\"].clamp(min=0, max=1), target, data_range=1.0, size_average=True)\n",
    "        out[\"psnr_loss\"] = self.psnr(output[\"x_hat\"].clamp(min=0, max=1), target, data_range=1.0)\n",
    "        out[\"loss\"] = self.lmbda * 255 ** 2 * out[\"psnr_loss\"] + out[\"bpp_loss\"]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ea36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Compute running average.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7022824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataParallel(nn.DataParallel):\n",
    "    \"\"\"Custom DataParallel to access the module methods.\"\"\"\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return super().__getattr__(key)\n",
    "        except AttributeError:\n",
    "            return getattr(self.module, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e6f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(net, learning_rate, aux_learning_rate):\n",
    "    \"\"\"Separate parameters for the main optimizer and the auxiliary optimizer.\n",
    "    Return two optimizers\"\"\"\n",
    "\n",
    "    parameters = {\n",
    "        n\n",
    "        for n, p in net.named_parameters()\n",
    "        if not n.endswith(\".quantiles\") and p.requires_grad\n",
    "    }\n",
    "    aux_parameters = {\n",
    "        n\n",
    "        for n, p in net.named_parameters()\n",
    "        if n.endswith(\".quantiles\") and p.requires_grad\n",
    "    }\n",
    "\n",
    "    # Make sure we don't have an intersection of parameters\n",
    "    params_dict = dict(net.named_parameters())\n",
    "    inter_params = parameters & aux_parameters\n",
    "    union_params = parameters | aux_parameters\n",
    "\n",
    "    assert len(inter_params) == 0\n",
    "    assert len(union_params) - len(params_dict.keys()) == 0\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        (params_dict[n] for n in sorted(parameters)),\n",
    "        lr=learning_rate,\n",
    "    )\n",
    "    aux_optimizer = optim.Adam(\n",
    "        (params_dict[n] for n in sorted(aux_parameters)),\n",
    "        lr=aux_learning_rate,\n",
    "    )\n",
    "    return optimizer, aux_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4622dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    loss = AverageMeter()\n",
    "    bpp_loss = AverageMeter()\n",
    "    msssim_loss = AverageMeter()\n",
    "    psnr_loss = AverageMeter()\n",
    "    aux_loss = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in test_dataloader:\n",
    "            d = d.to(device)\n",
    "            out_net = model(d)\n",
    "            out_criterion = criterion(out_net, d)\n",
    "\n",
    "            aux_loss.update(model.aux_loss())\n",
    "            bpp_loss.update(out_criterion[\"bpp_loss\"])\n",
    "            loss.update(out_criterion[\"loss\"])\n",
    "            msssim_loss.update(out_criterion[\"msssim_loss\"])\n",
    "            psnr_loss.update(out_criterion[\"psnr_loss\"])\n",
    "\n",
    "    print(\n",
    "        f\"Average losses:\"\n",
    "        f\"\\tLoss: {loss.avg:.3f} |\"\n",
    "        f\"\\tMS-SSIM loss: {msssim_loss.avg:.3f} |\"\n",
    "        f\"\\tPSNR loss: {psnr_loss.avg:.3f} |\"\n",
    "        f\"\\tBpp loss: {bpp_loss.avg:.2f} |\"\n",
    "        f\"\\tAux loss: {aux_loss.avg:.2f}\\n\"\n",
    "    )\n",
    "\n",
    "    return [bpp_loss.avg, msssim_loss.avg, psnr_loss.avg];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa8329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modelname(model, quality, loss_fn, reference_trained):\n",
    "    return model + \"_q\" + str(quality) + \"_\" + loss_fn + (\"_ref\" if reference_trained else \"_special\")\n",
    "\n",
    "def create_filename(model, quality, loss_fn, target_epochs):\n",
    "    return model + \"_q\" + str(quality) + \"_\" + loss_fn + \"_\" + str(target_epochs) + \"ep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4596fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (512, 512)\n",
    "dataset = \"/home/clemens/Documents/TU Wien/2021W/Bachelor Thesis/datasets/selection\"\n",
    "model_dir = \"/home/clemens/Documents/TU Wien/2021W/Bachelor Thesis/final_training\"\n",
    "ref_model_dir = \"/home/clemens/Documents/TU Wien/2021W/Bachelor Thesis/reference_training\"\n",
    "batch_size = 8\n",
    "test_batch_size=2\n",
    "num_workers = 8\n",
    "epoch_final = 500\n",
    "lmbda = {\n",
    "    'mse': {\n",
    "        1: 0.0018,\n",
    "        2: 0.0035,\n",
    "        3: 0.0067,\n",
    "        4: 0.0130,\n",
    "        5: 0.0250,\n",
    "        6: 0.0483,\n",
    "        7: 0.0932,\n",
    "        8: 0.1800\n",
    "    },\n",
    "    'msssim': {\n",
    "        1: 2.4,\n",
    "        2: 4.58,\n",
    "        3: 8.73,\n",
    "        4: 16.64,\n",
    "        5: 31.37,\n",
    "        6: 60.5,\n",
    "        7: 115.37,\n",
    "        8: 220\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff3fa59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose(\n",
    "    [transforms.CenterCrop(patch_size), transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "test_dataset = ImageFolder(dataset, split=\"test\", transform=test_transforms)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=(device == \"cuda\"),\n",
    ")\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d000b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for /home/clemens/Documents/TU Wien/2021W/Bachelor Thesis/final_training/mbt2018_q4_mse_500ep.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/clemens/.conda/envs/venv-ba/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/clemens/.conda/envs/venv-ba/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/clemens/.conda/envs/venv-ba/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/clemens/.conda/envs/venv-ba/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50501/1750672368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mepoch_final\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WARNING: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_label_custom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" has \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", desired: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_label_custom\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_50501/2126013337.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(test_dataloader, model, criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mout_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mout_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0maux_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_50501/1569079542.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, target)\u001b[0m\n\u001b[1;32m     18\u001b[0m         )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"msssim_loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mms_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x_hat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"psnr_loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x_hat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmbda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"psnr_loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bpp_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/venv-ba/lib/python3.9/site-packages/pytorch_msssim/ssim.py\u001b[0m in \u001b[0;36mms_ssim\u001b[0;34m(X, Y, data_range, size_average, win_size, win_sigma, win, weights, K)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0448\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2856\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2363\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1333\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Models trained with animated images \"\"\"\n",
    "model = \"mbt2018\"\n",
    "for quality in [4,6,8]: \n",
    "    for metric in [\"mse\", \"msssim\"]:\n",
    "        filename = model_dir + '/' + create_filename(model, quality, metric, epoch_final) + \".pth.tar\"\n",
    "        print(\"checking for \" + filename)\n",
    "        if os.path.exists(filename):\n",
    "            net = models[model](quality=quality, pretrained=False)\n",
    "            net = net.to(device)\n",
    "            \n",
    "            if torch.cuda.device_count() > 1:\n",
    "                net = CustomDataParallel(net)\n",
    "            \n",
    "            criterion = RateDistortionLoss(lmbda=lmbda[metric][quality])\n",
    "            \n",
    "            checkpoint = torch.load(filename, map_location=device)\n",
    "            net.load_state_dict(checkpoint[\"state_dict\"])\n",
    "            model_label_custom = create_modelname(model, quality, metric, False)\n",
    "            if checkpoint[\"epoch\"] + 1 != epoch_final:\n",
    "                print(\"WARNING: \" + model_label_custom + \" has \" + checkpoint[\"epoch\"] + 1 + \", desired: \" + epoch_final)\n",
    "            losses = test_model(test_dataloader, net, criterion)\n",
    "            results[model_label_custom] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Models trained with generic photographs \"\"\"\n",
    "model = \"mbt2018\"\n",
    "for quality in [4,6,8]: \n",
    "    for metric in [\"mse\", \"msssim\"]:\n",
    "        filename = ref_model_dir + '/' + create_filename(model, quality, metric, epoch_final) + \".pth.tar\"\n",
    "        print(\"checking for \" + filename)\n",
    "        if os.path.exists(filename):\n",
    "            net = models[model](quality=quality, pretrained=False)\n",
    "            net = net.to(device)\n",
    "            \n",
    "            if torch.cuda.device_count() > 1:\n",
    "                net = CustomDataParallel(net)\n",
    "            \n",
    "            criterion = RateDistortionLoss(lmbda=lmbda[metric][quality])\n",
    "            \n",
    "            checkpoint = torch.load(filename, map_location=device)\n",
    "            net.load_state_dict(checkpoint[\"state_dict\"])\n",
    "            model_label_custom = create_modelname(model, quality, metric, True)\n",
    "            if checkpoint[\"epoch\"] + 1 != epoch_final:\n",
    "                print(\"WARNING: \" + model_label_custom + \" has \" + checkpoint[\"epoch\"] + 1 + \", desired: \" + epoch_final)\n",
    "            losses = test_model(test_dataloader, net, criterion)\n",
    "            results[model_label_custom] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(map(lambda item: item[0], results.items()))\n",
    "bpp = list(map(lambda item: item[1][0].item(), results.items()))\n",
    "msssim = list(map(lambda item: item[1][1].item(), results.items()))\n",
    "psnr = list(map(lambda item: item[1][2].item(), results.items()))\n",
    "df = pd.DataFrame({\n",
    "    'bpp': bpp,\n",
    "    'msssim': msssim,\n",
    "    'psnr': psnr,\n",
    "    'model': map(lambda item: item.split(\"_\")[0], labels),\n",
    "    'quality': map(lambda item: int(item.split(\"_\")[1][1:]), labels),\n",
    "    'metric': map(lambda item: item.split(\"_\")[2], labels),\n",
    "    'training': map(lambda item: item.split(\"_\")[3], labels)\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c75cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 300\n",
    "fig, ax = plt.subplots()\n",
    "model=\"mbt2018\"\n",
    "for training in [\"vanilla\", \"custom\"]:\n",
    "    for metric in [\"mse\", \"msssim\"]:\n",
    "        line, = ax.plot(\n",
    "            'bpp',\n",
    "            'psnr',\n",
    "            data=df[df['model'] == model][df['metric'] == metric][df['training'] == training],\n",
    "            label=model + \" \" + metric + \" \" + training, linestyle=(':' if training == 'custom' else '-'),\n",
    "            marker='o'\n",
    "        )\n",
    "for bpp, psnr, quality in zip(df['bpp'], df['psnr'], df['quality']):\n",
    "    ax.annotate('%s' % quality, xy=(bpp, psnr), xytext=(10,-10), textcoords='offset points')\n",
    "fig.set_figwidth(8)\n",
    "fig.set_figheight(6)\n",
    "ax.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
